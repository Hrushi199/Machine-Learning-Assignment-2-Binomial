{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e5ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using Device: cuda\n",
      "Loading Data...\n",
      "Feature Engineering...\n",
      "Starting 5-Fold Training with params: {'lr': 0.005, 'weight_decay': 0.0001, 'batch_size': 2048, 'epochs': 50}\n",
      "  Fold 1/5...\n",
      "  Fold 2/5...\n",
      "  Fold 3/5...\n",
      "  Fold 4/5...\n",
      "  Fold 5/5...\n",
      "\n",
      "Final Macro F1: 0.7472 at Threshold: 0.500\n",
      "Saved 'submission_logreg_gpu.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP & REPRODUCIBILITY\n",
    "# ============================================================================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Using Device: {device}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. PREPROCESSING (LINEAR MODEL SPECIALIZED)\n",
    "# ============================================================================\n",
    "print(\"Loading Data...\")\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Handle IDs\n",
    "test_ids = df_test['founder_id'].copy()\n",
    "df_train.drop('founder_id', axis=1, inplace=True)\n",
    "df_test.drop('founder_id', axis=1, inplace=True)\n",
    "\n",
    "# Target Map\n",
    "df_train['retention_status'] = df_train['retention_status'].map({'Left': 1, 'Stayed': 0})\n",
    "y = df_train['retention_status'].values\n",
    "X = df_train.drop('retention_status', axis=1)\n",
    "X_test = df_test \n",
    "\n",
    "def process_linear(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Text Clean\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.replace('â€™', \"'\").str.replace('â€˜', \"'\")\n",
    "        \n",
    "    # 2. Binary Mapping\n",
    "    bin_cols = ['working_overtime', 'remote_operations', 'leadership_scope', 'innovation_support']\n",
    "    for c in bin_cols:\n",
    "        df[c] = df[c].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "\n",
    "    # 3. Numeric Imputation (Median)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for c in num_cols:\n",
    "        df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "    # 4. Feature Engineering (Ratios help Linear Models A LOT)\n",
    "    def safe_div(a, b): return np.where(b > 0, a / b, 0)\n",
    "    \n",
    "    # Create simple ordinal map for size to use in math\n",
    "    size_map = {'Small': 10, 'Medium': 50, 'Large': 200, 'Unknown': 25}\n",
    "    size_approx = df['team_size_category'].map(size_map).fillna(25)\n",
    "    \n",
    "    df['revenue_per_employee'] = safe_div(df['monthly_revenue_generated'], size_approx)\n",
    "    df['funding_per_year'] = safe_div(df['funding_rounds_led'], df['years_since_founding'])\n",
    "    df['age_entry_diff'] = df['founder_age'] - df['years_with_startup']\n",
    "    \n",
    "    # 5. Log Transform Skewed Numericals\n",
    "    df['log_revenue'] = np.log1p(df['monthly_revenue_generated'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Feature Engineering...\")\n",
    "X_proc = process_linear(X)\n",
    "X_test_proc = process_linear(X_test)\n",
    "\n",
    "# --- ONE-HOT ENCODING & SCALING ---\n",
    "# Linear models need One-Hot for nominals\n",
    "cat_cols = ['founder_gender', 'founder_role', 'personal_status', 'team_size_category', \n",
    "            'founder_visibility', 'education_background', 'startup_stage', \n",
    "            'work_life_balance_rating', 'startup_performance_rating', \n",
    "            'startup_reputation', 'venture_satisfaction']\n",
    "\n",
    "# Get dummies (One-Hot)\n",
    "X_proc = pd.get_dummies(X_proc, columns=cat_cols, dummy_na=True)\n",
    "X_test_proc = pd.get_dummies(X_test_proc, columns=cat_cols, dummy_na=True)\n",
    "\n",
    "# Align columns (ensure test has same columns as train)\n",
    "X_proc, X_test_proc = X_proc.align(X_test_proc, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Scale Everything\n",
    "scaler = StandardScaler()\n",
    "X_arr = scaler.fit_transform(X_proc)\n",
    "X_test_arr = scaler.transform(X_test_proc)\n",
    "\n",
    "# Convert to Float32 for GPU\n",
    "X_tensor = torch.tensor(X_arr, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_arr, dtype=torch.float32)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PYTORCH LOGISTIC REGRESSION MODEL\n",
    "# ============================================================================\n",
    "class LogisticRegressionGPU(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionGPU, self).__init__()\n",
    "        # 1 Linear Layer + Sigmoid = Logistic Regression\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class DataHelper(Dataset):\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None: return self.x[idx], self.y[idx]\n",
    "        return self.x[idx]\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FINAL TRAINING (5-FOLD CV)\n",
    "# ============================================================================\n",
    "# Fixed Parameters (Robust defaults)\n",
    "params = {\n",
    "    'lr': 0.005,\n",
    "    'weight_decay': 1e-4,\n",
    "    'batch_size': 2048,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "print(f\"Starting 5-Fold Training with params: {params}\")\n",
    "\n",
    "# Train on 5-Fold Averaging for stability\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "test_preds_accum = np.zeros(len(X_test_tensor))\n",
    "oof_preds = np.zeros(len(X_tensor))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_tensor, y)):\n",
    "    print(f\"  Fold {fold+1}/5...\")\n",
    "    \n",
    "    # Prepare\n",
    "    X_tr, X_val = X_tensor[train_idx], X_tensor[val_idx]\n",
    "    y_tr, y_val = y_tensor[train_idx], y_tensor[val_idx]\n",
    "    train_loader = DataLoader(DataHelper(X_tr, y_tr), batch_size=params['batch_size'], shuffle=True)\n",
    "    \n",
    "    # Init\n",
    "    model = LogisticRegressionGPU(X_tensor.shape[1]).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(params['epochs']):\n",
    "        for x_b, y_b in train_loader:\n",
    "            x_b, y_b = x_b.to(device), y_b.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x_b)\n",
    "            loss = criterion(out, y_b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # OOF\n",
    "        val_probs = torch.sigmoid(model(X_val.to(device))).cpu().numpy()\n",
    "        oof_preds[val_idx] = val_probs.flatten()\n",
    "        \n",
    "        # Test\n",
    "        test_out = model(X_test_tensor.to(device))\n",
    "        test_preds_accum += torch.sigmoid(test_out).cpu().numpy().flatten() / 5\n",
    "\n",
    "# ============================================================================\n",
    "# 5. THRESHOLD OPTIMIZATION & SUBMISSION\n",
    "# ============================================================================\n",
    "# Optimize Threshold\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "for t in np.arange(0.3, 0.7, 0.001):\n",
    "    p = (oof_preds >= t).astype(int)\n",
    "    f1 = f1_score(y, p, average='macro')\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"\\nFinal Macro F1: {best_f1:.4f} at Threshold: {best_thresh:.3f}\")\n",
    "\n",
    "final_preds = (test_preds_accum >= best_thresh).astype(int)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'founder_id': test_ids,\n",
    "    'retention_status': ['Left' if p == 1 else 'Stayed' for p in final_preds]\n",
    "})\n",
    "sub.to_csv('submission_logreg_gpu.csv', index=False)\n",
    "print(\"Saved 'submission_logreg_gpu.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
