{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d55685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Processing Features...\n",
      "\n",
      "Starting Optuna Optimization (20 Trials)...\n",
      "\n",
      "Best AUC: 0.8480\n",
      "Best Params: {'iterations': 1413, 'learning_rate': 0.01710412620510586, 'depth': 4, 'l2_leaf_reg': 6, 'random_strength': 0.3970029344689633, 'bagging_temperature': 0.13502716667068476}\n",
      "\n",
      "Training Final Model with Best Params...\n",
      "0:\ttest: 0.7546617\tbest: 0.7546617 (0)\ttotal: 58.9ms\tremaining: 1m 23s\n",
      "200:\ttest: 0.8395654\tbest: 0.8395654 (200)\ttotal: 12.4s\tremaining: 1m 14s\n",
      "400:\ttest: 0.8457705\tbest: 0.8457705 (400)\ttotal: 25.9s\tremaining: 1m 5s\n",
      "600:\ttest: 0.8472586\tbest: 0.8472586 (600)\ttotal: 40.8s\tremaining: 55.2s\n",
      "800:\ttest: 0.8478862\tbest: 0.8478917 (791)\ttotal: 55.4s\tremaining: 42.3s\n",
      "1000:\ttest: 0.8479816\tbest: 0.8480042 (953)\ttotal: 1m 9s\tremaining: 28.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8480042172\n",
      "bestIteration = 953\n",
      "\n",
      "Shrink model to first 954 iterations.\n",
      "Optimized Threshold: 0.47 (Val Acc: 0.7544)\n",
      "Saved 'submission_optuna.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # Keep output clean\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATA PREP (Reuse the robust pipeline)\n",
    "# ============================================================================\n",
    "print(\"Loading Data...\")\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Clean Text\n",
    "def clean_text(df):\n",
    "    cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('’', \"'\").str.replace('‘', \"'\")\n",
    "    return df\n",
    "\n",
    "df_train = clean_text(df_train)\n",
    "df_test = clean_text(df_test)\n",
    "\n",
    "# Handle IDs & Target\n",
    "test_ids = df_test['founder_id'].copy()\n",
    "df_train.drop('founder_id', axis=1, inplace=True)\n",
    "df_test.drop('founder_id', axis=1, inplace=True)\n",
    "df_train['retention_status'] = df_train['retention_status'].map({'Left': 1, 'Stayed': 0}).fillna(0)\n",
    "y = df_train['retention_status']\n",
    "df_train.drop('retention_status', axis=1, inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "def process_features(df):\n",
    "    df = df.copy()\n",
    "    # Binary\n",
    "    for c in ['working_overtime', 'remote_operations', 'leadership_scope', 'innovation_support']:\n",
    "        df[c] = df[c].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "    \n",
    "    def safe_ratio(a, b): return np.where((b!=0) & (~pd.isna(b)), a/b, 0)\n",
    "    \n",
    "    # Ratios & Interactions\n",
    "    df['funding_velocity'] = safe_ratio(df['funding_rounds_led'], df['years_since_founding'])\n",
    "    size_map = {'Small': 1, 'Medium': 2, 'Large': 3, 'Unknown': 0}\n",
    "    df['team_complexity'] = df['remote_operations'] * df['team_size_category'].map(size_map).fillna(0)\n",
    "    df['revenue_per_year'] = safe_ratio(df['monthly_revenue_generated'], df['years_since_founding'])\n",
    "    df['founder_tenure_ratio'] = safe_ratio(df['years_with_startup'], df['years_since_founding'])\n",
    "    df['is_married'] = (df['personal_status'] == 'Married').astype(int)\n",
    "    df['family_burden'] = df['num_dependents'].fillna(0) * df['is_married']\n",
    "\n",
    "    # Ordinal Maps\n",
    "    bal_map = {'Poor':1, 'Fair':2, 'Good':3, 'Excellent':4, 'Unknown': 2}\n",
    "    perf_map = {'Poor':1, 'Average':2, 'Good':3, 'Excellent':4, 'Unknown': 2}\n",
    "    rep_map  = {'Poor':1, 'Fair':2, 'Good':3, 'Excellent':4, 'Unknown': 2}\n",
    "    sat_map  = {'Low':1, 'Medium':2, 'High':3, 'Very High':4, 'Unknown': 2}\n",
    "\n",
    "    # Mappings\n",
    "    df['work_pressure'] = df['working_overtime'] * (5 - df['work_life_balance_rating'].fillna('Unknown').map(bal_map))\n",
    "    \n",
    "    # Super Features (Success, Stage-Tenure, Burnout)\n",
    "    df['success_score'] = (df['startup_performance_rating'].map(perf_map).fillna(2) + \\\n",
    "                           df['startup_reputation'].map(rep_map).fillna(2) + \\\n",
    "                           df['venture_satisfaction'].map(sat_map).fillna(2)) / 3\n",
    "    df['stage_tenure'] = df['startup_stage'].map({'Entry':1, 'Mid':2, 'Senior':3, 'Unknown':0}).fillna(0) * df['founder_tenure_ratio']\n",
    "    df['burnout_index'] = df['work_pressure'] * df['family_burden']\n",
    "\n",
    "    # Fill Categoricals for CatBoost\n",
    "    nom_cols = ['founder_gender', 'founder_role', 'personal_status', 'team_size_category', 'founder_visibility', \n",
    "                'education_background', 'startup_stage', 'work_life_balance_rating', \n",
    "                'startup_performance_rating', 'startup_reputation', 'venture_satisfaction']\n",
    "    for col in nom_cols:\n",
    "        df[col] = df[col].fillna('Unknown').astype(str)\n",
    "        \n",
    "    # Binning\n",
    "    df['revenue_binned'] = pd.cut(df['monthly_revenue_generated'], bins=[-1, 5000, 8000, np.inf], labels=[0,1,2]).astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Processing Features...\")\n",
    "X = process_features(df_train)\n",
    "X_test_final = process_features(df_test)\n",
    "\n",
    "# Outliers & Impute\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "for col in ['monthly_revenue_generated', 'distance_from_investor_hub']:\n",
    "    up = X[col].quantile(0.99)\n",
    "    X[col] = np.clip(X[col], None, up)\n",
    "    X_test_final[col] = np.clip(X_test_final[col], None, up)\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X[num_cols] = imputer.fit_transform(X[num_cols])\n",
    "X_test_final[num_cols] = imputer.transform(X_test_final[num_cols])\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "cat_features = ['founder_gender', 'founder_role', 'personal_status', 'team_size_category', 'founder_visibility', \n",
    "                'education_background', 'startup_stage', 'work_life_balance_rating', \n",
    "                'startup_performance_rating', 'startup_reputation', 'venture_satisfaction']\n",
    "\n",
    "# ============================================================================\n",
    "# 2. OPTUNA OPTIMIZATION\n",
    "# ============================================================================\n",
    "def objective(trial):\n",
    "    # The Search Space\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 1000, 3000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'border_count': 254,\n",
    "        'loss_function': 'Logloss',\n",
    "        'eval_metric': 'AUC',\n",
    "        'cat_features': cat_features,\n",
    "        'verbose': False,\n",
    "        'random_seed': 42,\n",
    "        'early_stopping_rounds': 50\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "    \n",
    "    preds = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, preds)\n",
    "    return auc\n",
    "\n",
    "print(\"\\nStarting Optuna Optimization (100 Trials)...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(f\"\\nBest AUC: {study.best_value:.4f}\")\n",
    "print(\"Best Params:\", study.best_params)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. FINAL TRAINING & SUBMISSION\n",
    "# ============================================================================\n",
    "print(\"\\nTraining Final Model with Best Params...\")\n",
    "best_params = study.best_params\n",
    "best_params['cat_features'] = cat_features\n",
    "best_params['verbose'] = 200\n",
    "best_params['eval_metric'] = 'AUC'\n",
    "best_params['early_stopping_rounds'] = 50\n",
    "\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "\n",
    "# Threshold Tuning\n",
    "val_probs = final_model.predict_proba(X_val)[:, 1]\n",
    "best_acc = 0\n",
    "best_t = 0.5\n",
    "for t in np.arange(0.30, 0.70, 0.01):\n",
    "    acc = accuracy_score(y_val, (val_probs >= t).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_t = t\n",
    "\n",
    "print(f\"Optimized Threshold: {best_t:.2f} (Val Acc: {best_acc:.4f})\")\n",
    "\n",
    "# Predict\n",
    "test_probs = final_model.predict_proba(X_test_final)[:, 1]\n",
    "test_preds = (test_probs >= best_t).astype(int)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'founder_id': test_ids,\n",
    "    'retention_status': ['Left' if p == 1 else 'Stayed' for p in test_preds]\n",
    "})\n",
    "sub.to_csv('submission_optuna.csv', index=False)\n",
    "print(\"Saved 'submission_optuna.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353143c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Processing Features...\n",
      "Encoding and Scaling...\n",
      "\n",
      "Subsampling 20% of training data for speed...\n",
      "Training on 9537 rows (subset) instead of 47688...\n",
      "Validation AUC: 0.8373\n",
      "\n",
      "Tuning Threshold...\n",
      "Optimized Threshold: 0.43 (Val Acc: 0.7445)\n",
      "Saved 'submission_fast_svm.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATA PREP\n",
    "# ============================================================================\n",
    "print(\"Loading Data...\")\n",
    "try:\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Files not found, generating dummy data...\")\n",
    "    # Dummy data generator for demonstration\n",
    "    data = {\n",
    "        'founder_id': range(1000),\n",
    "        'retention_status': np.random.choice(['Left', 'Stayed'], 1000),\n",
    "        'working_overtime': np.random.choice(['Yes', 'No'], 1000),\n",
    "        'remote_operations': np.random.choice(['Yes', 'No'], 1000),\n",
    "        'monthly_revenue_generated': np.random.rand(1000) * 10000,\n",
    "        'years_since_founding': np.random.rand(1000) * 10,\n",
    "        'team_size_category': np.random.choice(['Small', 'Medium', 'Large'], 1000),\n",
    "        # Add minimal required columns for script to run if files missing\n",
    "    }\n",
    "    df_train = pd.DataFrame(data)\n",
    "    df_test = pd.DataFrame(data).drop('retention_status', axis=1)\n",
    "\n",
    "# Clean Text\n",
    "def clean_text(df):\n",
    "    cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.replace('’', \"'\").str.replace('‘', \"'\")\n",
    "    return df\n",
    "\n",
    "df_train = clean_text(df_train)\n",
    "df_test = clean_text(df_test)\n",
    "\n",
    "# Handle IDs & Target\n",
    "test_ids = df_test['founder_id'].copy()\n",
    "df_train.drop('founder_id', axis=1, inplace=True)\n",
    "df_test.drop('founder_id', axis=1, inplace=True)\n",
    "\n",
    "# Map Target\n",
    "if 'retention_status' in df_train.columns:\n",
    "    df_train['retention_status'] = df_train['retention_status'].map({'Left': 1, 'Stayed': 0}).fillna(0)\n",
    "    y = df_train['retention_status']\n",
    "    df_train.drop('retention_status', axis=1, inplace=True)\n",
    "else:\n",
    "    y = np.zeros(len(df_train))\n",
    "\n",
    "# Feature Engineering\n",
    "def process_features(df):\n",
    "    df = df.copy()\n",
    "    # Binary\n",
    "    for c in ['working_overtime', 'remote_operations', 'leadership_scope', 'innovation_support']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].map({'Yes': 1, 'No': 0}).fillna(0).astype(int)\n",
    "    \n",
    "    # Ratios & Interactions (Simplified)\n",
    "    def safe_ratio(a, b): return np.where((b!=0) & (~pd.isna(b)), a/b, 0)\n",
    "    \n",
    "    if 'funding_rounds_led' in df.columns:\n",
    "        df['funding_velocity'] = safe_ratio(df['funding_rounds_led'], df['years_since_founding'])\n",
    "    \n",
    "    size_map = {'Small': 1, 'Medium': 2, 'Large': 3, 'Unknown': 0}\n",
    "    if 'team_size_category' in df.columns:\n",
    "        df['team_complexity'] = df['remote_operations'] * df['team_size_category'].map(size_map).fillna(0)\n",
    "    \n",
    "    # Fill Categoricals\n",
    "    nom_cols = ['founder_gender', 'founder_role', 'personal_status', 'team_size_category', 'founder_visibility', \n",
    "                'education_background', 'startup_stage', 'work_life_balance_rating', \n",
    "                'startup_performance_rating', 'startup_reputation', 'venture_satisfaction']\n",
    "    \n",
    "    for col in nom_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna('Unknown').astype(str)\n",
    "            \n",
    "    return df\n",
    "\n",
    "print(\"Processing Features...\")\n",
    "X = process_features(df_train)\n",
    "X_test_final = process_features(df_test)\n",
    "\n",
    "# Impute Numerics\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X[num_cols] = imputer.fit_transform(X[num_cols])\n",
    "X_test_final[num_cols] = imputer.transform(X_test_final[num_cols])\n",
    "\n",
    "# ============================================================================\n",
    "# SVM PREP\n",
    "# ============================================================================\n",
    "print(\"Encoding and Scaling...\")\n",
    "\n",
    "# 1. One-Hot Encoding\n",
    "n_train = len(X)\n",
    "combined = pd.concat([X, X_test_final], axis=0)\n",
    "combined = pd.get_dummies(combined, drop_first=True)\n",
    "\n",
    "X = combined.iloc[:n_train]\n",
    "X_test_final = combined.iloc[n_train:]\n",
    "\n",
    "# 2. Scaling\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X_test_final = pd.DataFrame(scaler.transform(X_test_final), columns=X_test_final.columns)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. FAST TRAINING (LinearSVC + 20% Data)\n",
    "# ============================================================================\n",
    "print(\"\\nSubsampling 20% of training data for speed...\")\n",
    "\n",
    "# Sample 20% of indices\n",
    "train_subset_idx = np.random.choice(X_train.index, size=int(len(X_train) * 0.20), replace=False)\n",
    "X_train_sub = X_train.loc[train_subset_idx]\n",
    "y_train_sub = y_train.loc[train_subset_idx]\n",
    "\n",
    "print(f\"Training on {len(X_train_sub)} rows (subset) instead of {len(X_train)}...\")\n",
    "\n",
    "# Use LinearSVC wrapped in CalibratedClassifierCV\n",
    "# LinearSVC is much faster than SVC(kernel='rbf')\n",
    "# CalibratedClassifierCV allows us to still get .predict_proba()\n",
    "linear_svc = LinearSVC(dual=False, random_state=42, C=1.0)\n",
    "model = CalibratedClassifierCV(linear_svc, cv=3) \n",
    "\n",
    "model.fit(X_train_sub, y_train_sub)\n",
    "\n",
    "# Evaluate\n",
    "preds_prob = model.predict_proba(X_val)[:, 1]\n",
    "auc_score = roc_auc_score(y_val, preds_prob)\n",
    "print(f\"Validation AUC: {auc_score:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. SUBMISSION\n",
    "# ============================================================================\n",
    "print(\"\\nTuning Threshold...\")\n",
    "best_acc = 0\n",
    "best_t = 0.5\n",
    "for t in np.arange(0.30, 0.70, 0.01):\n",
    "    acc = accuracy_score(y_val, (preds_prob >= t).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_t = t\n",
    "\n",
    "print(f\"Optimized Threshold: {best_t:.2f} (Val Acc: {best_acc:.4f})\")\n",
    "\n",
    "# Predict\n",
    "test_probs = model.predict_proba(X_test_final)[:, 1]\n",
    "test_preds = (test_probs >= best_t).astype(int)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    'founder_id': test_ids,\n",
    "    'retention_status': ['Left' if p == 1 else 'Stayed' for p in test_preds]\n",
    "})\n",
    "sub.to_csv('submission_fast_svm.csv', index=False)\n",
    "print(\"Saved 'submission_fast_svm.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
